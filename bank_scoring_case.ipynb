{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bank_scoring_case.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0RkvIpmABIX"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvtt1Q0pAESZ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSdTLFs9AW-U"
      },
      "source": [
        "# Read the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-gRbbPMAFsW"
      },
      "source": [
        "\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/bank-scoring-case/X_train.csv\")\n",
        "df_y_train = pd.read_csv(\"/content/drive/MyDrive/bank-scoring-case/y_train.csv\")\n",
        "y_test_sample = pd.read_csv(\"/content/drive/MyDrive/bank-scoring-case/y_test_sample.csv\", index_col=\"index\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/bank-scoring-case/X_test.csv\", index_col=\"index\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buUUTRinAbyF"
      },
      "source": [
        "# Wrappers for the test and train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGnVWB-AAVnI"
      },
      "source": [
        "class train_set(Dataset):\n",
        "    '''\n",
        "    before using dataloader, we have to wrap our train and validation dataset with the following function\n",
        "    '''\n",
        "    def __init__(self, df,features, labels):\n",
        "        self.val = df[features]\n",
        "        self.labels = labels\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.val)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        feat_tensors = torch.FloatTensor(self.val.iloc[idx])\n",
        "        labels_tensors = torch.FloatTensor(self.labels.iloc[idx])\n",
        "        return feat_tensors, labels_tensors\n",
        "\n",
        "    \n",
        "class test_set(Dataset):\n",
        "    '''\n",
        "    wrapper for the test set\n",
        "    '''\n",
        "    def __init__(self, df, feature):\n",
        "        self.val = df[feature].values\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.val)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        feat_tensors = torch.FloatTensor(self.val[idx])\n",
        "        return feat_tensors"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNNp786AAl_C"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxHvsjzVAO6E"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    #the following neural network was taken from https://towardsdatascience.com/pytorch-tabular-binary-classification-a0368da5bb89\n",
        "    #I was just searching for what might work best for tabular data, I will probably change this NN in the following submissions\n",
        "    #but I think just trying existed NN is a good point to start.\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()        \n",
        "        self.layer_1 = nn.Linear(8, 64) \n",
        "        self.layer_2 = nn.Linear(64, 32)\n",
        "        \n",
        "        self.layer_out = nn.Linear(32, 1) \n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        \n",
        "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(32)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        x = self.relu(self.layer_1(inputs))\n",
        "        x = self.batchnorm1(x)\n",
        "        \n",
        "        x = self.relu(self.layer_2(x))\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.layer_out(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBo5KnGECxoh"
      },
      "source": [
        "# For Neural Networks, i used 5 seeds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdPDGGbbAoOW"
      },
      "source": [
        "\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    #this function was taken from one of the notebooks of kaggle competition moa prediction\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nt4QVmlAAuNC"
      },
      "source": [
        "# Train, validate and test(infere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7n8tsbaAqJj"
      },
      "source": [
        "def train_model(model, train_loader, optimizer, criterion):\n",
        "    loss_epoch = 0\n",
        "    acc = 0\n",
        "    model.train()\n",
        "    for X, y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        predicted = model(X)\n",
        "        \n",
        "        loss = criterion(predicted, y)\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            pred = torch.round(torch.sigmoid(predicted))\n",
        "            accuracy =  accuracy_score(pred, y) * 100\n",
        "            \n",
        "        loss_epoch += loss.item()\n",
        "        acc += accuracy\n",
        "        \n",
        "    return loss/len(train_loader), acc/len(train_loader) \n",
        "        \n",
        "\n",
        "def validate_model(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    \n",
        "    val_preds = []\n",
        "    loss_epoch = 0\n",
        "    acc = 0\n",
        "    \n",
        "    for X, y in val_loader:\n",
        "        with torch.no_grad():\n",
        "            y_pred = model(X)\n",
        "            predicted = torch.round(torch.sigmoid(y_pred))\n",
        "            accuracy =  accuracy_score(predicted, y) * 100\n",
        "        \n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "        acc += accuracy\n",
        "        loss_epoch += loss.item()\n",
        "        \n",
        "    return loss_epoch/len(val_loader), acc/len(val_loader)\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    \n",
        "    y_pred_list = []\n",
        "    \n",
        "    for X in test_loader:\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            y_pred = model(X)\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "            #predicted = torch.round(torch.sigmoid(y_pred))\n",
        "            #y_pred_list.append(predicted.cpu().numpy())\n",
        "            y_pred_list.append(y_pred.cpu().numpy())\n",
        "    y_pred_list = np.concatenate(y_pred_list)        \n",
        "    return y_pred_list "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWTDktbOBN0j"
      },
      "source": [
        "# Run different seeds\n",
        "So the idea is following: divide the data into 5 parts using StartifiedKFold and each time train and validate the model for 10 epochs, the model with best validation accuracy is used predict test set, this predictions(probabilities) is divided by 5(since we have 5 partitions). So do it for all 5 partitions.(sum all of these predictions/5). This is one seed, we have such 5 seeds. Sum of all predictions of each seed, again have to be divided by 5 since we are doing 5 seeds.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITJAW1BTAzuC",
        "outputId": "b715492a-e341-4f8d-f2f6-20506a93bd16"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "features = df_train.columns \n",
        "nan_cols = ['monthly_income', 'family_members']#remove the columns which have missing value\n",
        "#I am removing at all the columns whic have missing values, because even thought I impute them, it worsen the result\n",
        "#For montly income I imputed by mean and median,I also tried to add the column is_Imputed (1 if yes, 0 for no),\n",
        "#but it turns out we are doing better without them\n",
        "features = [i for i in features if i not in nan_cols]\n",
        "predicted_seed = np.zeros((len(df_test), 1))\n",
        "skf = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\n",
        "    \n",
        "for seed in [1, 2, 3, 4, 5]:\n",
        "    print(f'Seed: {seed}')\n",
        "    seed_everything(seed = seed)\n",
        "    predicted = np.zeros((len(df_test), 1))\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(df_train, df_y_train)):\n",
        "\n",
        "        train_data = train_set(df_train.loc[train_index], features, df_y_train.loc[train_index])\n",
        "        val_data = train_set(df_train.loc[val_index], features, df_y_train.loc[val_index])\n",
        "\n",
        "        train_loader = DataLoader(dataset=train_data, batch_size= 64, shuffle=True)\n",
        "\n",
        "        val_loader = DataLoader(dataset=val_data, batch_size=64)\n",
        "\n",
        "        print(f'fold: {fold}') \n",
        "        model = Net()\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "        best_val = np.inf\n",
        "        for i in range(10):\n",
        "            loss, acc = train_model(model, train_loader, optimizer, criterion)\n",
        "            val_loss, val_acc = validate_model(model, val_loader, criterion)\n",
        "            print(f'{i}: train: {acc:.2f} and val {val_acc:.2f}')\n",
        "            if val_loss < best_val:\n",
        "                best_val = val_loss\n",
        "                print('Torch is saving..')\n",
        "                torch.save(model.state_dict(), f\"model_{seed}_{fold}.pth\")\n",
        "        model = Net()\n",
        "        model.load_state_dict(torch.load(f\"model_{seed}_{fold}.pth\"))\n",
        "\n",
        "        test_data = test_set(df_test, features)\n",
        "\n",
        "        test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle = False, pin_memory = True)\n",
        "\n",
        "        _predicted = test_model(model, test_loader)\n",
        "        predicted += _predicted/5\n",
        "    predicted_seed += predicted/5\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed: 1\n",
            "fold: 0\n",
            "0: train: 90.55 and val 93.39\n",
            "Torch is saving..\n",
            "1: train: 93.44 and val 93.31\n",
            "2: train: 93.53 and val 93.29\n",
            "Torch is saving..\n",
            "3: train: 93.54 and val 93.57\n",
            "Torch is saving..\n",
            "4: train: 93.55 and val 93.49\n",
            "5: train: 93.53 and val 93.56\n",
            "6: train: 93.56 and val 93.46\n",
            "7: train: 93.56 and val 93.36\n",
            "8: train: 93.54 and val 93.49\n",
            "9: train: 93.62 and val 93.24\n",
            "fold: 1\n",
            "0: train: 90.75 and val 93.29\n",
            "Torch is saving..\n",
            "1: train: 93.43 and val 93.42\n",
            "Torch is saving..\n",
            "2: train: 93.51 and val 93.36\n",
            "Torch is saving..\n",
            "3: train: 93.53 and val 93.47\n",
            "Torch is saving..\n",
            "4: train: 93.50 and val 93.69\n",
            "Torch is saving..\n",
            "5: train: 93.57 and val 93.42\n",
            "6: train: 93.53 and val 93.44\n",
            "Torch is saving..\n",
            "7: train: 93.61 and val 93.52\n",
            "8: train: 93.60 and val 93.55\n",
            "9: train: 93.57 and val 93.44\n",
            "fold: 2\n",
            "0: train: 91.86 and val 93.35\n",
            "Torch is saving..\n",
            "1: train: 93.45 and val 93.37\n",
            "Torch is saving..\n",
            "2: train: 93.51 and val 93.39\n",
            "3: train: 93.50 and val 93.24\n",
            "Torch is saving..\n",
            "4: train: 93.54 and val 93.43\n",
            "Torch is saving..\n",
            "5: train: 93.57 and val 93.18\n",
            "6: train: 93.55 and val 93.46\n",
            "7: train: 93.57 and val 93.39\n",
            "8: train: 93.61 and val 93.51\n",
            "9: train: 93.57 and val 93.27\n",
            "fold: 3\n",
            "0: train: 92.08 and val 93.59\n",
            "Torch is saving..\n",
            "1: train: 93.47 and val 93.53\n",
            "Torch is saving..\n",
            "2: train: 93.55 and val 93.48\n",
            "Torch is saving..\n",
            "3: train: 93.52 and val 93.44\n",
            "4: train: 93.54 and val 93.37\n",
            "5: train: 93.62 and val 93.48\n",
            "6: train: 93.62 and val 93.60\n",
            "7: train: 93.59 and val 93.35\n",
            "8: train: 93.63 and val 93.33\n",
            "9: train: 93.62 and val 93.61\n",
            "fold: 4\n",
            "0: train: 91.96 and val 93.30\n",
            "Torch is saving..\n",
            "1: train: 93.45 and val 93.38\n",
            "2: train: 93.49 and val 93.43\n",
            "Torch is saving..\n",
            "3: train: 93.48 and val 93.61\n",
            "4: train: 93.47 and val 93.31\n",
            "5: train: 93.47 and val 93.33\n",
            "6: train: 93.50 and val 93.38\n",
            "7: train: 93.54 and val 93.28\n",
            "8: train: 93.52 and val 93.38\n",
            "9: train: 93.53 and val 93.47\n",
            "Seed: 2\n",
            "fold: 0\n",
            "0: train: 91.09 and val 93.34\n",
            "Torch is saving..\n",
            "1: train: 93.53 and val 93.43\n",
            "Torch is saving..\n",
            "2: train: 93.53 and val 93.33\n",
            "3: train: 93.54 and val 93.43\n",
            "Torch is saving..\n",
            "4: train: 93.54 and val 93.36\n",
            "5: train: 93.56 and val 93.49\n",
            "Torch is saving..\n",
            "6: train: 93.58 and val 93.52\n",
            "Torch is saving..\n",
            "7: train: 93.56 and val 93.44\n",
            "Torch is saving..\n",
            "8: train: 93.60 and val 93.38\n",
            "9: train: 93.63 and val 93.42\n",
            "fold: 1\n",
            "0: train: 90.75 and val 93.33\n",
            "Torch is saving..\n",
            "1: train: 93.40 and val 93.42\n",
            "Torch is saving..\n",
            "2: train: 93.48 and val 93.39\n",
            "Torch is saving..\n",
            "3: train: 93.54 and val 93.55\n",
            "4: train: 93.54 and val 93.33\n",
            "5: train: 93.54 and val 93.32\n",
            "6: train: 93.52 and val 93.31\n",
            "Torch is saving..\n",
            "7: train: 93.57 and val 93.35\n",
            "8: train: 93.58 and val 93.32\n",
            "9: train: 93.47 and val 93.46\n",
            "fold: 2\n",
            "0: train: 91.88 and val 93.33\n",
            "Torch is saving..\n",
            "1: train: 93.39 and val 93.40\n",
            "Torch is saving..\n",
            "2: train: 93.50 and val 93.65\n",
            "3: train: 93.53 and val 93.36\n",
            "4: train: 93.54 and val 93.53\n",
            "Torch is saving..\n",
            "5: train: 93.54 and val 93.51\n",
            "Torch is saving..\n",
            "6: train: 93.57 and val 93.43\n",
            "7: train: 93.53 and val 93.31\n",
            "8: train: 93.58 and val 93.14\n",
            "9: train: 93.57 and val 93.30\n",
            "fold: 3\n",
            "0: train: 92.52 and val 93.65\n",
            "Torch is saving..\n",
            "1: train: 93.49 and val 92.73\n",
            "2: train: 93.56 and val 93.32\n",
            "3: train: 93.47 and val 93.30\n",
            "4: train: 93.57 and val 93.35\n",
            "Torch is saving..\n",
            "5: train: 93.57 and val 93.38\n",
            "6: train: 93.54 and val 93.28\n",
            "Torch is saving..\n",
            "7: train: 93.58 and val 93.47\n",
            "Torch is saving..\n",
            "8: train: 93.57 and val 93.33\n",
            "9: train: 93.61 and val 93.18\n",
            "fold: 4\n",
            "0: train: 90.93 and val 93.50\n",
            "Torch is saving..\n",
            "1: train: 93.49 and val 93.53\n",
            "Torch is saving..\n",
            "2: train: 93.46 and val 93.40\n",
            "3: train: 93.49 and val 93.40\n",
            "Torch is saving..\n",
            "4: train: 93.47 and val 93.49\n",
            "Torch is saving..\n",
            "5: train: 93.48 and val 93.40\n",
            "6: train: 93.52 and val 93.37\n",
            "7: train: 93.55 and val 93.41\n",
            "Torch is saving..\n",
            "8: train: 93.56 and val 93.75\n",
            "9: train: 93.52 and val 93.48\n",
            "Seed: 3\n",
            "fold: 0\n",
            "0: train: 92.59 and val 93.25\n",
            "Torch is saving..\n",
            "1: train: 93.47 and val 93.39\n",
            "Torch is saving..\n",
            "2: train: 93.49 and val 93.37\n",
            "3: train: 93.53 and val 93.50\n",
            "Torch is saving..\n",
            "4: train: 93.66 and val 93.33\n",
            "Torch is saving..\n",
            "5: train: 93.50 and val 93.53\n",
            "Torch is saving..\n",
            "6: train: 93.58 and val 93.56\n",
            "7: train: 93.67 and val 93.41\n",
            "8: train: 93.57 and val 93.36\n",
            "9: train: 93.59 and val 93.70\n",
            "fold: 1\n",
            "0: train: 92.42 and val 93.34\n",
            "Torch is saving..\n",
            "1: train: 93.37 and val 93.44\n",
            "2: train: 93.49 and val 93.60\n",
            "Torch is saving..\n",
            "3: train: 93.47 and val 93.51\n",
            "4: train: 93.50 and val 93.55\n",
            "Torch is saving..\n",
            "5: train: 93.54 and val 93.42\n",
            "6: train: 93.58 and val 93.33\n",
            "7: train: 93.51 and val 93.34\n",
            "8: train: 93.55 and val 93.31\n",
            "9: train: 93.56 and val 93.31\n",
            "fold: 2\n",
            "0: train: 92.81 and val 93.34\n",
            "Torch is saving..\n",
            "1: train: 93.44 and val 93.33\n",
            "Torch is saving..\n",
            "2: train: 93.47 and val 93.46\n",
            "Torch is saving..\n",
            "3: train: 93.56 and val 93.38\n",
            "Torch is saving..\n",
            "4: train: 93.53 and val 93.35\n",
            "5: train: 93.56 and val 93.42\n",
            "6: train: 93.60 and val 93.41\n",
            "Torch is saving..\n",
            "7: train: 93.59 and val 93.63\n",
            "8: train: 93.65 and val 93.62\n",
            "Torch is saving..\n",
            "9: train: 93.54 and val 93.46\n",
            "fold: 3\n",
            "0: train: 90.70 and val 93.40\n",
            "Torch is saving..\n",
            "1: train: 93.45 and val 93.47\n",
            "2: train: 93.50 and val 93.39\n",
            "Torch is saving..\n",
            "3: train: 93.51 and val 93.58\n",
            "4: train: 93.57 and val 93.41\n",
            "Torch is saving..\n",
            "5: train: 93.53 and val 93.55\n",
            "Torch is saving..\n",
            "6: train: 93.54 and val 93.52\n",
            "7: train: 93.55 and val 93.39\n",
            "8: train: 93.63 and val 93.47\n",
            "Torch is saving..\n",
            "9: train: 93.61 and val 93.44\n",
            "fold: 4\n",
            "0: train: 92.12 and val 93.54\n",
            "Torch is saving..\n",
            "1: train: 93.48 and val 93.63\n",
            "Torch is saving..\n",
            "2: train: 93.44 and val 93.62\n",
            "Torch is saving..\n",
            "3: train: 93.54 and val 93.44\n",
            "Torch is saving..\n",
            "4: train: 93.54 and val 93.53\n",
            "5: train: 93.57 and val 93.66\n",
            "6: train: 93.59 and val 93.29\n",
            "7: train: 93.57 and val 93.31\n",
            "8: train: 93.55 and val 93.32\n",
            "9: train: 93.51 and val 93.37\n",
            "Seed: 4\n",
            "fold: 0\n",
            "0: train: 92.14 and val 93.45\n",
            "Torch is saving..\n",
            "1: train: 93.47 and val 93.49\n",
            "Torch is saving..\n",
            "2: train: 93.52 and val 93.33\n",
            "Torch is saving..\n",
            "3: train: 93.55 and val 93.49\n",
            "Torch is saving..\n",
            "4: train: 93.53 and val 93.40\n",
            "5: train: 93.55 and val 93.35\n",
            "6: train: 93.60 and val 93.54\n",
            "7: train: 93.60 and val 93.41\n",
            "Torch is saving..\n",
            "8: train: 93.62 and val 93.37\n",
            "9: train: 93.65 and val 93.40\n",
            "fold: 1\n",
            "0: train: 91.35 and val 93.31\n",
            "Torch is saving..\n",
            "1: train: 93.45 and val 93.43\n",
            "Torch is saving..\n",
            "2: train: 93.49 and val 93.42\n",
            "Torch is saving..\n",
            "3: train: 93.54 and val 93.31\n",
            "4: train: 93.56 and val 93.49\n",
            "5: train: 93.55 and val 93.58\n",
            "Torch is saving..\n",
            "6: train: 93.56 and val 93.31\n",
            "7: train: 93.54 and val 93.35\n",
            "8: train: 93.51 and val 93.43\n",
            "9: train: 93.59 and val 92.34\n",
            "fold: 2\n",
            "0: train: 91.93 and val 93.33\n",
            "Torch is saving..\n",
            "1: train: 93.42 and val 93.28\n",
            "Torch is saving..\n",
            "2: train: 93.46 and val 93.30\n",
            "Torch is saving..\n",
            "3: train: 93.54 and val 93.36\n",
            "Torch is saving..\n",
            "4: train: 93.52 and val 93.36\n",
            "5: train: 93.56 and val 93.34\n",
            "6: train: 93.58 and val 93.36\n",
            "7: train: 93.53 and val 93.36\n",
            "8: train: 93.60 and val 93.34\n",
            "9: train: 93.54 and val 93.35\n",
            "fold: 3\n",
            "0: train: 92.25 and val 93.33\n",
            "Torch is saving..\n",
            "1: train: 93.48 and val 93.51\n",
            "Torch is saving..\n",
            "2: train: 93.52 and val 93.31\n",
            "3: train: 93.52 and val 93.37\n",
            "Torch is saving..\n",
            "4: train: 93.56 and val 93.47\n",
            "5: train: 93.55 and val 93.57\n",
            "Torch is saving..\n",
            "6: train: 93.62 and val 93.41\n",
            "7: train: 93.57 and val 93.42\n",
            "8: train: 93.68 and val 93.44\n",
            "9: train: 93.62 and val 93.45\n",
            "fold: 4\n",
            "0: train: 90.59 and val 93.45\n",
            "Torch is saving..\n",
            "1: train: 93.38 and val 93.47\n",
            "2: train: 93.50 and val 93.36\n",
            "Torch is saving..\n",
            "3: train: 93.47 and val 93.33\n",
            "4: train: 93.45 and val 93.72\n",
            "Torch is saving..\n",
            "5: train: 93.48 and val 93.35\n",
            "6: train: 93.52 and val 93.46\n",
            "Torch is saving..\n",
            "7: train: 93.50 and val 93.35\n",
            "8: train: 93.53 and val 93.62\n",
            "9: train: 93.58 and val 93.48\n",
            "Seed: 5\n",
            "fold: 0\n",
            "0: train: 92.15 and val 93.45\n",
            "Torch is saving..\n",
            "1: train: 93.50 and val 93.30\n",
            "Torch is saving..\n",
            "2: train: 93.49 and val 93.30\n",
            "3: train: 93.46 and val 93.57\n",
            "Torch is saving..\n",
            "4: train: 93.47 and val 93.48\n",
            "5: train: 93.60 and val 93.33\n",
            "6: train: 93.62 and val 92.42\n",
            "7: train: 93.63 and val 92.66\n",
            "8: train: 93.55 and val 93.60\n",
            "9: train: 93.56 and val 93.57\n",
            "fold: 1\n",
            "0: train: 91.34 and val 93.60\n",
            "Torch is saving..\n",
            "1: train: 93.46 and val 93.69\n",
            "Torch is saving..\n",
            "2: train: 93.45 and val 93.59\n",
            "Torch is saving..\n",
            "3: train: 93.53 and val 93.34\n",
            "4: train: 93.55 and val 93.58\n",
            "Torch is saving..\n",
            "5: train: 93.56 and val 93.69\n",
            "6: train: 93.58 and val 93.29\n",
            "7: train: 93.55 and val 93.06\n",
            "8: train: 93.60 and val 93.68\n",
            "9: train: 93.66 and val 92.57\n",
            "fold: 2\n",
            "0: train: 91.92 and val 93.33\n",
            "Torch is saving..\n",
            "1: train: 93.42 and val 93.37\n",
            "Torch is saving..\n",
            "2: train: 93.50 and val 93.36\n",
            "Torch is saving..\n",
            "3: train: 93.54 and val 93.52\n",
            "4: train: 93.54 and val 93.54\n",
            "Torch is saving..\n",
            "5: train: 93.61 and val 93.49\n",
            "Torch is saving..\n",
            "6: train: 93.55 and val 93.39\n",
            "7: train: 93.59 and val 93.53\n",
            "Torch is saving..\n",
            "8: train: 93.63 and val 93.47\n",
            "9: train: 93.56 and val 93.11\n",
            "fold: 3\n",
            "0: train: 92.50 and val 93.47\n",
            "Torch is saving..\n",
            "1: train: 93.46 and val 93.48\n",
            "2: train: 93.50 and val 93.34\n",
            "Torch is saving..\n",
            "3: train: 93.54 and val 93.65\n",
            "Torch is saving..\n",
            "4: train: 93.57 and val 93.29\n",
            "5: train: 93.62 and val 93.31\n",
            "Torch is saving..\n",
            "6: train: 93.59 and val 93.33\n",
            "7: train: 93.56 and val 93.63\n",
            "8: train: 93.56 and val 93.36\n",
            "9: train: 93.64 and val 93.38\n",
            "Torch is saving..\n",
            "fold: 4\n",
            "0: train: 91.04 and val 93.58\n",
            "Torch is saving..\n",
            "1: train: 93.43 and val 93.33\n",
            "Torch is saving..\n",
            "2: train: 93.49 and val 93.43\n",
            "Torch is saving..\n",
            "3: train: 93.53 and val 93.38\n",
            "4: train: 93.52 and val 93.61\n",
            "5: train: 93.57 and val 93.73\n",
            "6: train: 93.56 and val 93.60\n",
            "7: train: 93.51 and val 93.71\n",
            "8: train: 93.52 and val 93.43\n",
            "9: train: 93.54 and val 93.47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOIsHRMmC9vL"
      },
      "source": [
        "# Read the data2(for xgboost and randomforest)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXJ3HYgyA29-"
      },
      "source": [
        "\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/bank-scoring-case/X_train.csv\")\n",
        "df_y_train = pd.read_csv(\"/content/drive/MyDrive/bank-scoring-case/y_train.csv\")\n",
        "y_test_sample = pd.read_csv(\"/content/drive/MyDrive/bank-scoring-case/y_test_sample.csv\", index_col=\"index\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/bank-scoring-case/X_test.csv\", index_col=\"index\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AZN26feinEj"
      },
      "source": [
        "# GridSearch for best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tb0JkDLirtK"
      },
      "source": [
        "'''\n",
        "random_tree = RandomForestClassifier(random_state=42)\n",
        "\n",
        "features = df_train.columns \n",
        "nan_cols = ['monthly_income', 'family_members']\n",
        "features = [i for i in features if i not in nan_cols]\n",
        "\n",
        "param_grid = { \n",
        "    'n_estimators': [450, 500],\n",
        "    'max_depth' : [i for i in range(4, 16)],\n",
        "}\n",
        "\n",
        "\n",
        "grid = GridSearchCV(estimator=random_tree, param_grid=param_grid, cv= 5)\n",
        "grid.fit(df_train[features], df_y_train)\n",
        "\n",
        "\n",
        "xgb = XGBClassifier()\n",
        "param_grid2 = { \n",
        "    'n_estimators': [450, 500],\n",
        "    'max_depth' : [i for i in range(4, 16)],\n",
        "}\n",
        "\n",
        "\n",
        "grid2 = GridSearchCV(estimator=xgb, param_grid=param_grid2, cv= 5)\n",
        "grid2.fit(df_train[features], df_y_train)\n",
        "\n",
        "\n",
        "grid2.best_params_['n_estimators'] ---- > 450\n",
        "grid2.best_params_['max_depth'] ---->4\n",
        "\n",
        "grid.best_params_['n_estimators'] ---- > 450\n",
        "grid.best_params_['max_depth'] ---->10\n",
        "'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et5wG0dHDZV1"
      },
      "source": [
        "# XGBoost and RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYK96-8hA_WI",
        "outputId": "892daa10-e204-4d43-ab07-a53e615ea0b5"
      },
      "source": [
        "features = df_train.columns \n",
        "nan_cols = ['monthly_income', 'family_members']\n",
        "features = [i for i in features if i not in nan_cols]\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\n",
        "\n",
        "predicted = np.zeros((len(df_test), 1))\n",
        "predicted_xgb = np.zeros((len(df_test), 1))\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(df_train, df_y_train)):\n",
        "    train = df_train.loc[train_index, features]\n",
        "    y_train = df_y_train.loc[train_index]\n",
        "    val = df_train.loc[val_index, features]\n",
        "    y_val = df_y_train.loc[val_index]\n",
        "\n",
        "    random_tree = RandomForestClassifier(n_estimators = 450, max_depth = 10, n_jobs = -1)\n",
        "    \n",
        "    model = XGBClassifier(n_estimators = 450,  max_depth = 4)\n",
        "    model.fit(train, y_train)\n",
        "    \n",
        "    random_tree.fit(train, y_train)\n",
        "    accuracy = accuracy_score(y_val, random_tree.predict(val))\n",
        "    print(f'accuracy using random forest with 500 trees is {accuracy}')\n",
        "    predicted += random_tree.predict_proba(df_test[features])[:,1].reshape(-1,1)/5\n",
        "    predicted_xgb += model.predict_proba(df_test[features])[:,1].reshape(-1,1)/5"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy using random forest with 500 trees is 0.9374464846351441\n",
            "accuracy using random forest with 500 trees is 0.9372562077823233\n",
            "accuracy using random forest with 500 trees is 0.9371610693559128\n",
            "accuracy using random forest with 500 trees is 0.936970792503092\n",
            "accuracy using random forest with 500 trees is 0.9382522239665096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuLWQxtZDK0a"
      },
      "source": [
        "I multipied predictions from random forest and xgboost by 2 since they gave better results than NN indibidually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_qbhb3_BAWg"
      },
      "source": [
        "predicted = (2*predicted + predicted_seed + 2*predicted_xgb)/5\n",
        "\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "        \"index\": df_test.index,\n",
        "        \"target\": predicted.reshape(-1,)\n",
        "    })\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeJDhHNIBF3R"
      },
      "source": [
        "submission.to_csv('submission.csv', index=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}